{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test",
   "id": "2a8e9289390a0339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import packages",
   "id": "7ccfef15ecb25596"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.lite.python.schema_py_generated import Model\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from timm.data import create_dataset\n"
   ],
   "id": "ae3751a9d2721eda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.getcwd()",
   "id": "d9226f4475466134",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inspecting timm",
   "id": "41e9fff1c9e91a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(timm.list_models())",
   "id": "3a6dfc46a0442e63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(timm.list_models(pretrained=True))",
   "id": "11c6348359559301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load data",
   "id": "dc55c957c466e11d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Construct a tf.data.Dataset\n",
    "ds = tfds.load('mnist', split='train', as_supervised=True, shuffle_files=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.chdir(r'C:\\\\Users\\\\marti\\\\Desktop\\\\Škola\\\\Diplomova prace\\\\Imagenette\\\\Imagenette2')",
   "id": "57dee7948464f2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "noise_level = '5' # '5' or '50'\n",
    "outdir = 'noisy' + noise_level\n",
    "df = pd.read_csv('noisy_imagenette.csv', sep=',')\n",
    "for inpath, label, is_val in zip(df['path'], df['noisy_labels_' + noise_level], df['is_valid']):\n",
    "    if is_val:\n",
    "        subdir = 'val'\n",
    "    else:\n",
    "        subdir = 'train'\n",
    "    outpath = os.path.join(outdir, subdir, label)\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "    shutil.copy2(inpath, outpath)"
   ],
   "id": "66e7cd190285630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnist = load_dataset(\"ylecun/mnist\")"
   ],
   "id": "b668bf2fbad7409b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ],
   "id": "30aef06a2251a87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.chdir(r'C:\\\\Users\\\\marti\\\\Desktop\\\\Škola\\\\Diplomova prace\\\\CIFAR')",
   "id": "1017554c62b0b04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cifar = create_dataset('torch/cifar10', 'cifar10', download=True, split='train')",
   "id": "680632331ad0ab12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "d1f5412916abb448"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "timm.list_models('efficientnet*', pretrained=True)",
   "id": "67955d8d0d80c9f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = timm.create_model('resnet50d', pretrained=True, num_classes=10)",
   "id": "aca7236480d43755",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model",
   "id": "1b2dfd810818921a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# %%writefile train.py\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import timm\n",
    "import timm.data\n",
    "import timm.loss\n",
    "import timm.optim\n",
    "import timm.utils\n",
    "import torch\n",
    "import torchmetrics\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "\n",
    "from pytorch_accelerated.callbacks import SaveBestModelCallback\n",
    "from pytorch_accelerated.trainer import Trainer, DEFAULT_CALLBACKS\n",
    "\n",
    "\n",
    "def create_datasets(image_size, data_mean, data_std, train_path, val_path):\n",
    "    train_transforms = timm.data.create_transform(\n",
    "        input_size=image_size,\n",
    "        is_training=True,\n",
    "        mean=data_mean,\n",
    "        std=data_std,\n",
    "        auto_augment=\"rand-m7-mstd0.5-inc1\",\n",
    "    )\n",
    "\n",
    "    eval_transforms = timm.data.create_transform(\n",
    "        input_size=image_size, mean=data_mean, std=data_std\n",
    "    )\n",
    "\n",
    "    train_dataset = timm.data.dataset.ImageDataset(\n",
    "        train_path, transform=train_transforms\n",
    "    )\n",
    "    eval_dataset = timm.data.dataset.ImageDataset(val_path, transform=eval_transforms)\n",
    "\n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "\n",
    "class TimmMixupTrainer(Trainer):\n",
    "    def __init__(self, eval_loss_fn, mixup_args, num_classes, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.eval_loss_fn = eval_loss_fn\n",
    "        self.num_updates = None\n",
    "        self.mixup_fn = timm.data.Mixup(**mixup_args)\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(num_classes=num_classes)\n",
    "        self.ema_accuracy = torchmetrics.Accuracy(num_classes=num_classes)\n",
    "        self.ema_model = None\n",
    "\n",
    "    def create_scheduler(self):\n",
    "        return timm.scheduler.CosineLRScheduler(\n",
    "            self.optimizer,\n",
    "            t_initial=self.run_config.num_epochs,\n",
    "            cycle_decay=0.5,\n",
    "            lr_min=1e-6,\n",
    "            t_in_epochs=True,\n",
    "            warmup_t=3,\n",
    "            warmup_lr_init=1e-4,\n",
    "            cycle_limit=1,\n",
    "        )\n",
    "\n",
    "    def training_run_start(self):\n",
    "        # Model EMA requires the model without a DDP wrapper and before sync batchnorm conversion\n",
    "        self.ema_model = timm.utils.ModelEmaV2(\n",
    "            self._accelerator.unwrap_model(self.model), decay=0.9\n",
    "        )\n",
    "        if self.run_config.is_distributed:\n",
    "            self.model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(self.model)\n",
    "\n",
    "    def train_epoch_start(self):\n",
    "        super().train_epoch_start()\n",
    "        self.num_updates = self.run_history.current_epoch * len(self._train_dataloader)\n",
    "\n",
    "    def calculate_train_batch_loss(self, batch):\n",
    "        xb, yb = batch\n",
    "        mixup_xb, mixup_yb = self.mixup_fn(xb, yb)\n",
    "        return super().calculate_train_batch_loss((mixup_xb, mixup_yb))\n",
    "\n",
    "    def train_epoch_end(\n",
    "        self,\n",
    "    ):\n",
    "        self.ema_model.update(self.model)\n",
    "        self.ema_model.eval()\n",
    "\n",
    "        if hasattr(self.optimizer, \"sync_lookahead\"):\n",
    "            self.optimizer.sync_lookahead()\n",
    "\n",
    "    def scheduler_step(self):\n",
    "        self.num_updates += 1\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step_update(num_updates=self.num_updates)\n",
    "\n",
    "    def calculate_eval_batch_loss(self, batch):\n",
    "        with torch.no_grad():\n",
    "            xb, yb = batch\n",
    "            outputs = self.model(xb)\n",
    "            val_loss = self.eval_loss_fn(outputs, yb)\n",
    "            self.accuracy.update(outputs.argmax(-1), yb)\n",
    "\n",
    "            ema_model_preds = self.ema_model.module(xb).argmax(-1)\n",
    "            self.ema_accuracy.update(ema_model_preds, yb)\n",
    "\n",
    "        return {\"loss\": val_loss, \"model_outputs\": outputs, \"batch_size\": xb.size(0)}\n",
    "\n",
    "    def eval_epoch_end(self):\n",
    "        super().eval_epoch_end()\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step(self.run_history.current_epoch + 1)\n",
    "\n",
    "        self.run_history.update_metric(\"accuracy\", self.accuracy.compute().cpu())\n",
    "        self.run_history.update_metric(\n",
    "            \"ema_model_accuracy\", self.ema_accuracy.compute().cpu()\n",
    "        )\n",
    "        self.accuracy.reset()\n",
    "        self.ema_accuracy.reset()\n",
    "\n",
    "\n",
    "def main(data_path):\n",
    "\n",
    "    # Set training arguments, hardcoded here for clarity\n",
    "    image_size = (224, 224)\n",
    "    lr = 5e-3\n",
    "    smoothing = 0.1\n",
    "    mixup = 0.2\n",
    "    cutmix = 1.0\n",
    "    batch_size = 32\n",
    "    bce_target_thresh = 0.2\n",
    "    num_epochs = 40\n",
    "\n",
    "    data_path = Path(data_path)\n",
    "    train_path = data_path / \"train\"\n",
    "    val_path = data_path / \"val\"\n",
    "    num_classes = len(list(train_path.iterdir()))\n",
    "\n",
    "    mixup_args = dict(\n",
    "        mixup_alpha=mixup,\n",
    "        cutmix_alpha=cutmix,\n",
    "        label_smoothing=smoothing,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    # Create model using timm\n",
    "    model = timm.create_model(\n",
    "        \"resnet50d\", pretrained=False, num_classes=num_classes, drop_path_rate=0.05\n",
    "    )\n",
    "\n",
    "    # Load data config associated with the model to use in data augmentation pipeline\n",
    "    data_config = timm.data.resolve_data_config({}, model=model, verbose=True)\n",
    "    data_mean = data_config[\"mean\"]\n",
    "    data_std = data_config[\"std\"]\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    train_dataset, eval_dataset = create_datasets(\n",
    "        train_path=train_path,\n",
    "        val_path=val_path,\n",
    "        image_size=image_size,\n",
    "        data_mean=data_mean,\n",
    "        data_std=data_std,\n",
    "    )\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = timm.optim.create_optimizer_v2(\n",
    "        model, opt=\"lookahead_AdamW\", lr=lr, weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    # As we are using Mixup, we can use BCE during training and CE for evaluation\n",
    "    train_loss_fn = timm.loss.BinaryCrossEntropy(\n",
    "        target_threshold=bce_target_thresh, smoothing=smoothing\n",
    "    )\n",
    "    validate_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Create trainer and start training\n",
    "    trainer = TimmMixupTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=train_loss_fn,\n",
    "        eval_loss_fn=validate_loss_fn,\n",
    "        mixup_args=mixup_args,\n",
    "        num_classes=num_classes,\n",
    "        callbacks=[\n",
    "            *DEFAULT_CALLBACKS,\n",
    "            SaveBestModelCallback(watch_metric=\"accuracy\", greater_is_better=True),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer.train(\n",
    "        per_device_batch_size=batch_size,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        num_epochs=num_epochs,\n",
    "        create_scheduler_fn=trainer.create_scheduler,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Simple example of training script using timm.\")\n",
    "    parser.add_argument(\"--data_dir\", required=True, help=\"The data folder on disk.\")\n",
    "    args = parser.parse_args()\n",
    "    main(args.data_dir)"
   ],
   "id": "a1ede8213aa0fc4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())",
   "id": "78779de67eafb5b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "id": "cc39c6e802f07b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(os.path.exists('C:\\\\Users\\\\marti\\\\Desktop\\\\Škola\\\\Diplomova prace\\\\Imagenette\\imagenette2'))"
   ],
   "id": "cdf50e8f3db0b344",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "import random"
   ],
   "id": "2b7ad3111308737a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.require(\"core\")",
   "id": "ecb1a60d32373108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.login()",
   "id": "f794080ec6502258",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ],
   "id": "9b166ad0ca851a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "8b1dfba57f43c546",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.memory_summary())",
   "id": "58aa4f8c05cf398b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ],
   "id": "94835cff7035986b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.list_gpu_processes())",
   "id": "bdcc07952cb1362b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.mem_get_info())",
   "id": "8e60733d98e9ddf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.memory_stats())",
   "id": "61f6f252d6f1b5d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.memory_snapshot())",
   "id": "b7e03d0ea464ef2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.memory_allocated())",
   "id": "286a65ab4199bcac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.max_memory_allocated())",
   "id": "d80d1cfc90ca3a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.cuda.memory_reserved())",
   "id": "39a66697866bbbcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.cuda.reset_peak_memory_stats()",
   "id": "a5a84fd299fea4de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "import yaml\n",
    "from train import main\n",
    "\n",
    "# Load the sweeper.yaml configuration from the YAML file\n",
    "with open('sweep_config.yaml', 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)\n",
    "\n",
    "# Initialize the sweeper.yaml by passing the loaded config and project name\n",
    "sweep_id = wandb.sweep(sweep=sweep_config)\n",
    "\n",
    "# Start the sweeper.yaml agent, passing the main function\n",
    "# The count parameter specifies how many runs you want\n",
    "wandb.agent(sweep_id)"
   ],
   "id": "beacba0e346b9467",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.sweep(sweep=sweep_config)",
   "id": "439534087962cb0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "wandb.agent(sweep_id=\"rgcjpcod\", count=1)",
   "id": "c3b21a7d42817d21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T20:34:54.903247Z",
     "start_time": "2024-11-13T20:34:54.595193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the WandB API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify the project\n",
    "project_path = \"martinhruska_2000/Comparison200\"\n",
    "\n",
    "# Get all runs in the project\n",
    "runs = api.runs(project_path)"
   ],
   "id": "fa1a7a1431634880",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Runs martinhruska_2000/Comparison200>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T20:33:47.016857Z",
     "start_time": "2024-11-13T20:33:44.932447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize empty list to store data\n",
    "data = []\n",
    "\n",
    "# Loop over each run to retrieve metrics\n",
    "for run in runs:\n",
    "    # Get initialization strategy\n",
    "    initialization = run.config.get(\"initialization\", \"unknown\")\n",
    "\n",
    "    # Extract relevant metrics, ensuring numeric values only\n",
    "    eval_loss = pd.to_numeric(run.history(keys=[\"eval_loss\"])[\"eval_loss\"], errors=\"coerce\").dropna()\n",
    "    eval_top1 = pd.to_numeric(run.history(keys=[\"eval_top1\"])[\"eval_top1\"], errors=\"coerce\").dropna()\n",
    "    eval_top5 = pd.to_numeric(run.history(keys=[\"eval_top5\"])[\"eval_top5\"], errors=\"coerce\").dropna()\n",
    "    # grad_first1 = pd.to_numeric(run.history(keys=[\"grad_first1_l2\"])[\"grad_first1_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_first2 = pd.to_numeric(run.history(keys=[\"grad_first2_l2\"])[\"grad_first2_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_first3 = pd.to_numeric(run.history(keys=[\"grad_first3_l2\"])[\"grad_first3_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_first4 = pd.to_numeric(run.history(keys=[\"grad_first4_l2\"])[\"grad_first4_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_first5 = pd.to_numeric(run.history(keys=[\"grad_first5_l2\"])[\"grad_first5_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last1 = pd.to_numeric(run.history(keys=[\"grad_last1_l2\"])[\"grad_last1_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last2 = pd.to_numeric(run.history(keys=[\"grad_last2_l2\"])[\"grad_last2_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last3 = pd.to_numeric(run.history(keys=[\"grad_last3_l2\"])[\"grad_last3_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last4 = pd.to_numeric(run.history(keys=[\"grad_last4_l2\"])[\"grad_last4_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last5 = pd.to_numeric(run.history(keys=[\"grad_last5_l2\"])[\"grad_last5_l2\"], errors=\"coerce\").dropna()\n",
    "\n",
    "    # Append metrics to data if all lists have values\n",
    "    for loss, top1, top5, g_first1, g_first2, g_first3, g_first4, g_first5, g_last1, g_last2, g_last3, g_last4, g_last5 in zip(\n",
    "        eval_loss, eval_top1, eval_top5, grad_first1, grad_first2, grad_first3, grad_first4, grad_first5, grad_last1, grad_last2, grad_last3, grad_last4, grad_last5\n",
    "    ):\n",
    "        data.append({\n",
    "            \"initialization\": initialization,\n",
    "            \"eval_loss\": loss,\n",
    "            \"eval_top1\": top1,\n",
    "            \"eval_top5\": top5,\n",
    "            \"grad_first1_l2\": g_first1,\n",
    "            \"grad_first2_l2\": g_first2,\n",
    "            \"grad_first3_l2\": g_first3,\n",
    "            \"grad_first4_l2\": g_first4,\n",
    "            \"grad_first5_l2\": g_first5,\n",
    "            \"grad_last1_l2\": g_last1,\n",
    "            \"grad_last2_l2\": g_last2,\n",
    "            \"grad_last3_l2\": g_last3,\n",
    "            \"grad_last4_l2\": g_last4,\n",
    "            \"grad_last5_l2\": g_last5,\n",
    "        })\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by initialization and calculate summary statistics for each metric\n",
    "summary_stats = df.groupby(\"initialization\").agg([\"mean\", \"median\", \"std\"])\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_stats)"
   ],
   "id": "484f00c880c7b44a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'grad_first1_l2'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'grad_first1_l2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m eval_top1 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(run\u001B[38;5;241m.\u001B[39mhistory(keys\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval_top1\u001B[39m\u001B[38;5;124m\"\u001B[39m])[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval_top1\u001B[39m\u001B[38;5;124m\"\u001B[39m], errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[0;32m     12\u001B[0m eval_top5 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(run\u001B[38;5;241m.\u001B[39mhistory(keys\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval_top5\u001B[39m\u001B[38;5;124m\"\u001B[39m])[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval_top5\u001B[39m\u001B[38;5;124m\"\u001B[39m], errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[1;32m---> 13\u001B[0m grad_first1 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(\u001B[43mrun\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_first1_l2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_first1_l2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[0;32m     14\u001B[0m grad_first2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(run\u001B[38;5;241m.\u001B[39mhistory(keys\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_grad_first2_l2\u001B[39m\u001B[38;5;124m\"\u001B[39m])[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_grad_first2_l2\u001B[39m\u001B[38;5;124m\"\u001B[39m], errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[0;32m     15\u001B[0m grad_first3 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(run\u001B[38;5;241m.\u001B[39mhistory(keys\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_grad_first3_l2\u001B[39m\u001B[38;5;124m\"\u001B[39m])[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_grad_first3_l2\u001B[39m\u001B[38;5;124m\"\u001B[39m], errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'grad_first1_l2'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T20:42:29.547793Z",
     "start_time": "2024-11-13T20:42:28.926279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the list of logged metrics for the first run\n",
    "if runs:\n",
    "    run = runs[0]\n",
    "    # Get all keys (metrics) logged to this run\n",
    "    history = run.history()  # Returns a DataFrame with all metrics logged\n",
    "    metrics = history.columns  # List of all metric names\n",
    "\n",
    "    # Display the metric names\n",
    "    print(\"Logged Metrics:\")\n",
    "    for metric in metrics:\n",
    "        print(metric)\n",
    "\n",
    "    # Optional: Display sample data for each metric\n",
    "    print(\"\\nSample Data:\")\n",
    "    print(history.head())  # Show the first few rows of data\n",
    "else:\n",
    "    print(\"No runs found in the project.\")"
   ],
   "id": "5c76601e28e2e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Metrics:\n",
      "train_grad_classifier_last_l2\n",
      "lr\n",
      "eval_top1\n",
      "grad_bn1_first_l2\n",
      "eval_top5\n",
      "epoch\n",
      "train_loss\n",
      "train_grad_bn1_first_l2\n",
      "_runtime\n",
      "_step\n",
      "eval_loss\n",
      "grad_classifier_last_l2\n",
      "train_grad_conv_stem_first_l2\n",
      "_timestamp\n",
      "grad_conv_stem_first_l2\n",
      "\n",
      "Sample Data:\n",
      "   train_grad_classifier_last_l2  lr  eval_top1  grad_bn1_first_l2  eval_top5  \\\n",
      "0                            NaN NaN        NaN                NaN        NaN   \n",
      "1                            NaN NaN        NaN        4485.817871        NaN   \n",
      "2                            NaN NaN        NaN                NaN        NaN   \n",
      "3                            NaN NaN        NaN                NaN        NaN   \n",
      "4                            NaN NaN        NaN                NaN        NaN   \n",
      "\n",
      "   epoch  train_loss  train_grad_bn1_first_l2    _runtime  _step eval_loss  \\\n",
      "0      0         NaN                      NaN  144.823756      0      None   \n",
      "1      0         NaN                      NaN  144.824754      1      None   \n",
      "2      0         NaN                      NaN  144.824754      2      None   \n",
      "3      1         NaN                      NaN  291.369859      6      None   \n",
      "4      2         NaN                      NaN  409.697481      8      None   \n",
      "\n",
      "   grad_classifier_last_l2  train_grad_conv_stem_first_l2    _timestamp  \\\n",
      "0               306.962952                            NaN  1.730493e+09   \n",
      "1                      NaN                            NaN  1.730493e+09   \n",
      "2                      NaN                            NaN  1.730493e+09   \n",
      "3                      NaN                            NaN  1.730493e+09   \n",
      "4               317.293030                            NaN  1.730493e+09   \n",
      "\n",
      "   grad_conv_stem_first_l2  \n",
      "0                      NaN  \n",
      "1                      NaN  \n",
      "2             48184.949219  \n",
      "3               594.642151  \n",
      "4                      NaN  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T20:49:50.947389Z",
     "start_time": "2024-11-13T20:48:40.558101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize empty list to store data\n",
    "data = []\n",
    "\n",
    "# Loop over each run to retrieve metrics\n",
    "for run in runs:\n",
    "    # Get initialization strategy\n",
    "    initialization = run.config.get(\"initialization\", \"unknown\")\n",
    "\n",
    "    # Extract relevant metrics, ensuring numeric values only\n",
    "    eval_loss = pd.to_numeric(run.history(keys=[\"eval_loss\"])[\"eval_loss\"], errors=\"coerce\").dropna()\n",
    "    eval_top1 = pd.to_numeric(run.history(keys=[\"eval_top1\"])[\"eval_top1\"], errors=\"coerce\").dropna()\n",
    "    eval_top5 = pd.to_numeric(run.history(keys=[\"eval_top5\"])[\"eval_top5\"], errors=\"coerce\").dropna()\n",
    "    grad_classifier_last_l2 = pd.to_numeric(run.history(keys=[\"grad_classifier_last_l2\"])[\"grad_classifier_last_l2\"], errors=\"coerce\").dropna()\n",
    "    grad_bn1_first_l2 = pd.to_numeric(run.history(keys=[\"grad_bn1_first_l2\"])[\"grad_bn1_first_l2\"], errors=\"coerce\").dropna()\n",
    "    grad_conv_stem_first_l2 = pd.to_numeric(run.history(keys=[\"grad_conv_stem_first_l2\"])[\"grad_conv_stem_first_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_first4 = pd.to_numeric(run.history(keys=[\"train_grad_first4_l2\"])[\"train_grad_first4_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_first5 = pd.to_numeric(run.history(keys=[\"train_grad_first5_l2\"])[\"train_grad_first5_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last1 = pd.to_numeric(run.history(keys=[\"train_grad_last1_l2\"])[\"train_grad_last1_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last2 = pd.to_numeric(run.history(keys=[\"train_grad_last2_l2\"])[\"train_grad_last2_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last3 = pd.to_numeric(run.history(keys=[\"train_grad_last3_l2\"])[\"train_grad_last3_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last4 = pd.to_numeric(run.history(keys=[\"train_grad_last4_l2\"])[\"train_grad_last4_l2\"], errors=\"coerce\").dropna()\n",
    "    # grad_last5 = pd.to_numeric(run.history(keys=[\"train_grad_last5_l2\"])[\"train_grad_last5_l2\"], errors=\"coerce\").dropna()\n",
    "\n",
    "    # Append metrics to data if all lists have values\n",
    "    for loss, top1, top5, g_classifier_last_l2, g_bn1_first_l2, g_conv_stem_first_l2 in zip(\n",
    "        eval_loss, eval_top1, eval_top5, grad_classifier_last_l2, grad_bn1_first_l2, grad_conv_stem_first_l2\n",
    "    ):\n",
    "        data.append({\n",
    "            \"initialization\": initialization,\n",
    "            \"eval_loss\": loss,\n",
    "            \"eval_top1\": top1,\n",
    "            \"eval_top5\": top5,\n",
    "            \"grad_classifier_last_l2\": g_classifier_last_l2,\n",
    "            \"grad_bn1_first_l2\": g_bn1_first_l2,\n",
    "            \"grad_conv_stem_first_l2\": g_conv_stem_first_l2,\n",
    "        })\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by initialization and calculate summary statistics for each metric\n",
    "summary_stats = df.groupby(\"initialization\").agg([\"mean\", \"median\", \"std\"])\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_stats)"
   ],
   "id": "61ead4ca8aa895a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               eval_loss                      eval_top1                    \\\n",
      "                    mean    median       std       mean median        std   \n",
      "initialization                                                              \n",
      "goog            0.676778  0.551158  0.404998  80.405718  84.26  12.726949   \n",
      "he              0.845768  0.680184  0.541014  74.031098  79.58  15.589236   \n",
      "normal          0.693216  0.552274  0.419367  78.517342  82.32  13.596558   \n",
      "uniform         0.744234  0.601943  0.390350  78.482061  82.55  12.518836   \n",
      "xavier          0.759582  0.605189  0.471669  76.499155  81.32  15.041674   \n",
      "\n",
      "                eval_top5                  grad_classifier_last_l2  \\\n",
      "                     mean median       std                    mean   \n",
      "initialization                                                       \n",
      "goog            97.969295  99.02  4.397228              552.024513   \n",
      "he              96.646253  98.47  6.308088              827.003985   \n",
      "normal          97.691718  98.94  4.881570              314.134828   \n",
      "uniform         97.898728  98.87  3.492618              687.232008   \n",
      "xavier          97.216464  98.82  5.449430              706.261421   \n",
      "\n",
      "                                        grad_bn1_first_l2             \\\n",
      "                    median          std              mean     median   \n",
      "initialization                                                         \n",
      "goog            213.830307  1468.109126        121.107736  54.632912   \n",
      "he              241.643784  2475.198593        153.348640  52.827999   \n",
      "normal          153.183151   604.370633        102.343189  38.834747   \n",
      "uniform         166.780563  1727.498767        176.268917  47.562279   \n",
      "xavier          293.775696  2088.924327        168.632352  83.821457   \n",
      "\n",
      "                            grad_conv_stem_first_l2                             \n",
      "                        std                    mean       median           std  \n",
      "initialization                                                                  \n",
      "goog             326.241392             3630.469319  1973.052979   6109.794379  \n",
      "he               434.517380             4254.722491  1380.947388   8300.084331  \n",
      "normal           376.345172             3033.177648  1115.553467   6995.004577  \n",
      "uniform         1401.393447                     NaN  1539.284546           NaN  \n",
      "xavier           466.432172             5566.464121  2802.626465  18168.921694  \n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vidíme, že ve všech základních metrikách je nejlepší inicializace goog (neboli ta základní z knihovny timm). He inicializace je naopak nejhorší v těch základních metrikách. Gradienty jsou ještě špatně naprogramované (počet vrstev a názvy), ale jinak by měli fungovat. Zajímavé je, že druhá vrstva u uniform inicialiźace má oproti ostatním inicializacím velmi vysoké std a zároveň u poslední vrstvy dokonce má NaN jako mean a std. Očividně metrika top5 má nízké variace mezi inicializacemi. Normal inicializace je výrazně nejlepší v gradientech a jejich variaci. Další čeho si můžeme všimnout je fakt, že gradienty obecně, neboli jak mean, meadian, tak i std, tak se výrazně liší svojí magnitudou mezi vrstvami. Zatímco v první vrstvě jsou čísla velmi vysoká, tak v druhé jsou zase naopak velmi nízká.",
   "id": "8a166d1da771e9c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2674d56152a63b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
